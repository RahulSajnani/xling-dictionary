{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_details = dict()\n",
    "synonyms_dict = dict()\n",
    "keywords_done = set()\n",
    "language_ids = {\"Hindi\" : 0,\n",
    "                \"English\" : 1,\n",
    "                \"Bengali\": 3,\n",
    "                \"Gujarati\" : 5,\n",
    "                \"Marathi\" : 11,\n",
    "                \"Odiya\" : 18,\n",
    "                \"Punjabi\" : 16}\n",
    "\n",
    "gloss_snapshot_fname = \"snapshots/gloss_examples_SNAPSHOT\"\n",
    "synset_snapshot_fname = \"snapshots/synset_SNAPSHOT\"\n",
    "gloss_final_fname = \"gloss_final\"\n",
    "synset_final_fname = \"synset_final\"\n",
    "SNAPSHOT_INTERVAL = 3\n",
    "WAIT_THRESHOLD = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''file_path = \"./iwndata/punjabi.syns\"\n",
    "file = open(file_path, \"r\", encoding='utf-8')\n",
    "keywords = list()\n",
    "for line in tqdm(file.readlines()):\n",
    "    if line.startswith(\"SYN\"):\n",
    "        _, kws = line.split(\"::\")\n",
    "        kws = [x.strip() for x in kws.strip().split(\",\")]\n",
    "        if len(kws) > 0:\n",
    "            keywords.extend(kws)\n",
    "'''\n",
    "file_path = \"keywords.txt\"\n",
    "keywords = list()\n",
    "with open(file_path, \"r\", encoding='utf-8') as f:\n",
    "    for x in f.readlines():\n",
    "        keywords.append(x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_details(url):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "    except:\n",
    "        return\n",
    "    try:\n",
    "        details = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, 'detail'))\n",
    "        )\n",
    "    except:\n",
    "        return\n",
    "    try:\n",
    "        time.sleep(1)\n",
    "        soup = BeautifulSoup(details.get_attribute(\"innerHTML\"), 'html.parser')\n",
    "        result = soup.find(\"td\", {\"class\" : \"label1\"})\n",
    "        curr_details = dict()\n",
    "        data = list()\n",
    "        for x in result.find_all(\"span\"):\n",
    "            data.append(x.text)\n",
    "        result = soup.find(\"table\", {\"class\" : \"abc\"})\n",
    "\n",
    "        synset_id = result.find(\"label\", {\"id\" : \"sid\"}).text.strip()\n",
    "        synset_id = int(synset_id.strip())\n",
    "\n",
    "        if synset_id in synonyms_dict:\n",
    "            return\n",
    "\n",
    "        part_of_speech = result.find(\"label\", {\"id\" : \"pos\"}).text.strip()\n",
    "        curr_details['POS'] = part_of_speech\n",
    "\n",
    "        elem = driver.find_elements_by_class_name(\"semi_bar\")\n",
    "        buttons = elem[0].find_elements_by_class_name(\"title2\")\n",
    "        synonyms_data = dict()\n",
    "\n",
    "        for lang in language_ids:\n",
    "            buttons[language_ids[lang]].click()\n",
    "            '''\n",
    "            try:\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_all_elements_located((By.TAG_NAME, 'td'))\n",
    "                )\n",
    "            except:\n",
    "                pass    \n",
    "             '''\n",
    "            n_wait = 0\n",
    "            key = lang+\"_\"\n",
    "            while n_wait < WAIT_THRESHOLD:\n",
    "                rel_content = driver.find_elements_by_id('rel_content')\n",
    "                html_content = rel_content[0].get_attribute(\"innerHTML\")\n",
    "                if html_content != \"wait...\":\n",
    "                    break\n",
    "                time.sleep(1)\n",
    "                n_wait += 1\n",
    "            if n_wait == WAIT_THRESHOLD:\n",
    "                curr_details[key+\"gloss\"] = \"\"\n",
    "                curr_details[key+\"example\"] = \"\"\n",
    "                synonyms_data[lang] = list()\n",
    "                continue\n",
    "            mid_area_soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "\n",
    "            synonyms = list()\n",
    "            for syns in mid_area_soup.find_all(\"a\"):\n",
    "                #synonyms.append((syns.text.strip(), syns[\"href\"])) #uncomment for adding hrefs as well.\n",
    "                syn = syns.text.strip()\n",
    "                if lang == \"Punjabi\":\n",
    "                    keywords_done.add(syn)\n",
    "                synonyms.append(syn)\n",
    "            synonyms_data[lang] = synonyms\n",
    "            contents = mid_area_soup.find_all(\"td\", {\"class\" : \"content\"})\n",
    "\n",
    "            \n",
    "            gloss = \"\"\n",
    "            try:\n",
    "                gloss = contents[-2].text.strip() #Gloss\n",
    "            except:\n",
    "                pass\n",
    "            curr_details[key+\"gloss\"] = gloss\n",
    "\n",
    "            example = \"\"\n",
    "            try:\n",
    "                example = contents[-1].text.strip()\n",
    "            except:\n",
    "                pass\n",
    "            curr_details[key+\"example\"] = example.strip('\"')\n",
    "    except:\n",
    "        return\n",
    "    global_details[synset_id] = curr_details\n",
    "    synonyms_dict[synset_id] = synonyms_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_snapshot(cnt):\n",
    "    with open(gloss_snapshot_fname+str(cnt)+\".json\", \"w\") as f:\n",
    "        json.dump(global_details, f)\n",
    "    with open(synset_snapshot_fname+str(cnt)+\".json\", \"w\") as f:\n",
    "        json.dump(synonyms_dict, f)\n",
    "    print(\"Snapshot Generated for :\", cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_files():\n",
    "    with open(gloss_final_fname+\".json\", \"w\") as f:\n",
    "        json.dump(global_details, f)\n",
    "    with open(synset_final_fname+\".json\", \"w\") as f:\n",
    "        json.dump(synonyms_dict, f)\n",
    "    print(\"Final Dump Generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_details.clear()\n",
    "synonyms_dict.clear()\n",
    "keywords_done.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52797/52797 [00:45<00:00, 1159.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Dump Generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "last_done = 0\n",
    "for kw in tqdm(keywords):\n",
    "    #print(\"Fetching for keyword : \", kw)\n",
    "    if kw in keywords_done:\n",
    "        continue\n",
    "    query_url = r\"http://www.cfilt.iitb.ac.in/indowordnet/first?langno=16&queryword=\"+kw\n",
    "    fetch_details(query_url)\n",
    "    if len(global_details) % SNAPSHOT_INTERVAL == 0 and len(global_details) != last_done:\n",
    "        generate_snapshot(len(global_details))\n",
    "        last_done = len(global_details)\n",
    "        \n",
    "generate_final_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ਵਜਵਾਇਆ'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords[70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
